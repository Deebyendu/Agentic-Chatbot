# ğŸ¤– Agentic Chatbot â€” LangGraph Stateful Agentic AI

A full-stack, end-to-end agentic AI application built with **LangGraph**, **Streamlit**, and support for multiple LLMs (Groq & Mistral). The app enables stateful, multi-node AI graph workflows across three use cases: a basic chatbot, a web-search-enabled chatbot, and an AI news aggregator.

---

## ğŸ“¸ Preview

> Built with LangGraph state graphs, this app routes user interactions through dynamic AI nodes with conditional edges, tool integrations, and real-time Streamlit UI rendering.

---

## ğŸ—‚ï¸ Project Structure

```
E2E AGENTIC CHATBOT/
â”œâ”€â”€ AINews/                          # Output directory for generated news summaries
â”œâ”€â”€ src/
â”‚   â””â”€â”€ langgraphagenticai/
â”‚       â”œâ”€â”€ graph/
â”‚       â”‚   â””â”€â”€ graph_builder.py     # Builds LangGraph state graphs per use case
â”‚       â”œâ”€â”€ LLMS/
â”‚       â”‚   â”œâ”€â”€ groqllm.py           # Groq LLM initialization
â”‚       â”‚   â””â”€â”€ mistralllm.py        # Mistral LLM initialization
â”‚       â”œâ”€â”€ nodes/
â”‚       â”‚   â”œâ”€â”€ ai_news_node.py      # Fetch, summarize, and save AI news
â”‚       â”‚   â”œâ”€â”€ basic_chatbot_node.py        # Simple LLM chatbot node
â”‚       â”‚   â””â”€â”€ chatbot_with_tool_node.py    # LLM chatbot with tool binding
â”‚       â”œâ”€â”€ state/
â”‚       â”‚   â””â”€â”€ state.py             # Shared LangGraph state definition
â”‚       â”œâ”€â”€ tools/
â”‚       â”‚   â””â”€â”€ search_tool.py       # Tavily web search tool integration
â”‚       â””â”€â”€ ui/
â”‚           â””â”€â”€ streamlitui/
â”‚               â”œâ”€â”€ display_result.py    # Renders graph outputs in Streamlit
â”‚               â”œâ”€â”€ loadui.py            # Loads sidebar UI and user controls
â”‚               â”œâ”€â”€ uiconfigfile.ini     # UI configuration (models, titles, options)
â”‚               â””â”€â”€ uiconfigfile.py      # Config parser wrapper
â”‚           â””â”€â”€ main.py                  # App entry point logic
â”œâ”€â”€ app.py                           # Top-level entry point
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md
```

---

## ğŸš€ Features

- **Multi-LLM Support** â€” Switch between Groq and Mistral models from the sidebar without changing code.
- **Three Agentic Use Cases** â€” Each use case maps to a distinct LangGraph state graph:
  - ğŸ—¨ï¸ **Basic Chatbot** â€” Stateful single-node chatbot using any configured LLM.
  - ğŸŒ **Chatbot with Web Search** â€” LLM enhanced with Tavily web search using conditional tool-routing edges.
  - ğŸ“° **AI News** â€” A three-node pipeline (fetch â†’ summarize â†’ save) that retrieves and summarizes the latest AI news and writes it to a Markdown file.
- **LangGraph State Management** â€” All use cases use a typed `State` schema with LangGraph's `add_messages` annotation for message accumulation.
- **Streamlit UI** â€” Clean sidebar for LLM/model/use case selection and API key input, with inline chat and news rendering.
- **Config-Driven UI** â€” All labels, model lists, and use case options are driven by `uiconfigfile.ini` â€” no code changes needed to add new models.

---

## ğŸ§  How It Works

### State

All graphs share a common state schema defined in `state.py`:

```python
class State(TypedDict):
    messages: Annotated[List, add_messages]
```

This uses LangGraph's `add_messages` reducer to accumulate conversation history across graph nodes.

---

### Graph Architectures

#### 1. Basic Chatbot
```
START â†’ chatbot â†’ END
```
A single node that invokes the LLM directly on the current state messages.

#### 2. Chatbot with Web Search
```
START â†’ chatbot â”€â”€(tool call?)â”€â”€â–º tools
                â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        chatbot â†’ END
```
The LLM is bound with Tavily search tools. LangGraph's built-in `tools_condition` routes to the tool node when the LLM emits a tool call, then routes back to the chatbot for a final response.

#### 3. AI News Pipeline
```
START â†’ fetch_news â†’ summarize_news â†’ save_result â†’ END
```
A sequential three-node pipeline:
- **`fetch_news`** â€” Calls the Tavily API to retrieve top AI news (daily/weekly/monthly).
- **`summarize_news`** â€” Passes fetched articles to the LLM with a structured prompt to produce a dated, markdown-formatted summary.
- **`save_result`** â€” Writes the summary to `./AINews/{frequency}_summary.md`.

---

## âš™ï¸ Setup & Installation

### Prerequisites
- Python 3.9+
- API keys for:
  - [Groq](https://console.groq.com/keys) and/or [Mistral](https://console.mistral.ai/)
  - [Tavily](https://app.tavily.com/home) (required for Chatbot with Web and AI News use cases)

### Installation

```bash
# Clone the repository
git clone https://github.com/Deebyendu/Agentic-Chatbot.git
cd e2e-agentic-chatbot

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate       # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Running the App

```bash
streamlit run app.py
```

---

## ğŸ”‘ API Keys

API keys are entered securely via the Streamlit sidebar (password-masked inputs). They are never hardcoded. You will need:

| Key | Required For |
|---|---|
| `GROQ_API_KEY` | Basic Chatbot, Chatbot with Web (Groq models) |
| `MISTRAL_API_KEY` | Basic Chatbot, Chatbot with Web (Mistral models) |
| `TAVILY_API_KEY` | Chatbot with Web, AI News |

Optionally, you can set these as environment variables in a `.env` file:

```env
GROQ_API_KEY=your_groq_key
MISTRAL_API_KEY=your_mistral_key
TAVILY_API_KEY=your_tavily_key
```

---

## ğŸ§© Supported Models

Configured via `uiconfigfile.ini` â€” easily extensible.

**Groq:**
- `openai/gpt-oss-120b`
- `groq/compound`
- `qwen/qwen3-32b`

**Mistral:**
- `mistral-large-2512`
- `devstral-2512`
- `ministral-14b-latest`

---

## ğŸ“¦ Dependencies

```
langchain
langchain_community
langchain_groq
langchain-mistralai
langchain-tavily
langchain-classic
langgraph
tavily
faiss-cpu
streamlit
python-dotenv
```

---

## ğŸ“ AI News Output

When the **AI News** use case is run, a Markdown summary is saved to:

```
./AINews/daily_summary.md
./AINews/weekly_summary.md
./AINews/monthly_summary.md
```

The summary is formatted with dates (IST timezone), concise article summaries, and source URLs â€” sorted latest first.

---

## ğŸ”§ Configuration

To add new models or use cases, edit `uiconfigfile.ini`:

```ini
[DEFAULT]
PAGE_TITLE = LangGraph: Build Stateful Agentic AI graph
LLM_OPTIONS = Groq, Mistral
USECASE_OPTIONS = Basic Chatbot, Chatbot with Web, AI News
GROQ_MODEL_OPTIONS = openai/gpt-oss-120b, groq/compound, qwen/qwen3-32b
MISTRAL_MODEL_OPTIONS = mistral-large-2512, devstral-2512, ministral-14b-latest
```

No other code changes are required to reflect new models in the UI.

---

## ğŸ—ï¸ Extending the App

To add a new use case:

1. Create a new node file under `src/langgraphagenticai/nodes/`.
2. Register a new graph-building method in `graph_builder.py` and add it to `setup_graph()`.
3. Add display logic in `display_result.py` for the new use case.
4. Add the use case name to `USECASE_OPTIONS` in `uiconfigfile.ini`.

---

## ğŸ“„ License

This project is open source. See `LICENSE` for details.

---

## ğŸ™Œ Acknowledgements

- [LangGraph](https://github.com/langchain-ai/langgraph) â€” Stateful agentic graph framework
- [LangChain](https://github.com/langchain-ai/langchain) â€” LLM tooling and integrations
- [Tavily](https://tavily.com/) â€” AI-native web search API
- [Groq](https://groq.com/) â€” Ultra-fast LLM inference
- [Mistral AI](https://mistral.ai/) â€” Efficient open-weight LLMs
- [Streamlit](https://streamlit.io/) â€” Rapid Python UI framework
